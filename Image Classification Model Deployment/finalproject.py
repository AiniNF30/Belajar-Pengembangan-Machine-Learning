# -*- coding: utf-8 -*-
"""FinalProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MCPoYNy1ZDTUco9eSYMRIaxqcWAgl7dM
"""

# Directory
import os, zipfile, shutil

# Preprocessing and Layer
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dropout, Flatten, Dense
from keras_preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import MaxPooling2D, Dense, Dropout, Conv2D

# Plotting
import matplotlib.pyplot as plt

! pip install kaggle

from google.colab import files
files.upload()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/

!kaggle datasets download -d prasunroy/natural-images

local_zip = '/content/natural-images.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

#Defines the directory name for the train data and validation data.
main_dir = os.path.join('/content/data/natural_images')
print(os.listdir(main_dir))

ignore_dir = ['motorbike', 'flower', 'dog', 'cat', 'airplane']

for dir in ignore_dir:
  path = os.path.join(main_dir, dir)
  shutil.rmtree(path)

print(os.listdir(main_dir))

from PIL import Image
samples = 0

for x in os.listdir(main_dir):
  dir = os.path.join('/content/data/natural_images', x)
  y = len(os.listdir(dir))
  print(x+' :', y)
  samples = samples + y
  
  image_name = os.listdir(dir)
  for z in range(3):
    image_path = os.path.join(dir, image_name[z])
    image = Image.open(image_path)
    print(image.size)
  print()


print('Total Sample : ', samples)

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    horizontal_flip=True,
    shear_range = 0.2,
    zoom_range = 0.2,
    fill_mode = 'nearest',
    validation_split = 0.2)

train_generator = train_datagen.flow_from_directory(
    main_dir,
    target_size=(150, 150),
    batch_size=128,
    class_mode='categorical',
    subset='training')
 
validation_generator = train_datagen.flow_from_directory(
    main_dir,
    target_size=(150, 150),
    batch_size=128,
    class_mode='categorical',
    subset='validation')

class Callback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') and logs.get('val_accuracy') > 0.92):
      print("\n Sorry, data training was stopped because the accuracy rate was above 92%!")
      self.model.stop_training = True

callbacks = Callback()

model = Sequential()

model.add(Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3))),
model.add(MaxPooling2D(2, 2)),

model.add(Conv2D(64, (3,3), activation='relu')),
model.add(MaxPooling2D(2,2)),

model.add(Conv2D(128, (3,3), activation='relu')),
model.add(MaxPooling2D(2,2)),

model.add(Conv2D(128, (3,3), activation='relu')),
model.add(MaxPooling2D(2,2)),

model.add(Flatten()),

model.add(Dense(512, activation='relu')),
model.add(Dense(3, activation='softmax')),

model.summary()

model.compile(optimizer=tf.optimizers.Adam(),
              loss='categorical_crossentropy',
              metrics = ['accuracy'])

history = model.fit(
    train_generator,
    epochs= 100,
    validation_data=validation_generator,
    verbose=2,
    callbacks=[callbacks])

figure = plt.figure(figsize = (15, 5))

figure.add_subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy Plot')
plt.xlabel('Value')
plt.ylabel('Epoch')
plt.legend(['Train', 'Validation'], loc = 'lower right')

figure.add_subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Plot')
plt.xlabel('Value')
plt.ylabel('Epoch')
plt.legend(['Train', 'Validation'], loc = 'upper right')

save_path = 'mymodel/'
tf.saved_model.save(model, save_path)

converter = tf.lite.TFLiteConverter.from_saved_model(save_path)
tflite_model = converter.convert()
     
with tf.io.gfile.GFile('model_image_classification.tflite', 'wb') as f:
  f.write(tflite_model)